{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "import tensorflow as tf\n",
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''metadata=pd.read_csv(\"metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''metadata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''IMAGES_PATH=\"kaggle/images\"\n",
    "target_dir=\"datasets/datasets/train/positive\"\n",
    "for (i,row) in metadata.iterrows():\n",
    "    if row[\"finding\"]==\"COVID-19\" and row[\"view\"]==\"PA\":\n",
    "        filename=row[\"filename\"]\n",
    "        image_path=os.path.join(IMAGES_PATH,filename)\n",
    "        image_copy_path=os.path.join(target_dir,filename)\n",
    "        #print(image_path)\n",
    "        shutil.copy2(image_path,image_copy_path)\n",
    "''''        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "idg=tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20, # You can uncomment these parameters to make you generator rotate & flip the images to put the train model in stricter conditions.\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18126 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = idg.flow_from_directory(\"data1\",\n",
    "                                                   target_size=(128,128),                                                   \n",
    "                                                   subset='training',\n",
    "                                                   class_mode='binary',\n",
    "                                                   batch_size=32,\n",
    "                                                   shuffle=True,\n",
    "                                                   seed=1\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4531 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_gen = idg.flow_from_directory(\"data1\",\n",
    "                                                   target_size=(128,128),                                                   \n",
    "                                                   subset='validation',\n",
    "                                                   class_mode='binary',\n",
    "                                                   batch_size=32,\n",
    "                                                   shuffle=True,\n",
    "                                                   seed=1\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'covid': 0, 'normal': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 4, 4, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 23,538,690\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "input_shape = (128,128, 3)\n",
    "googleNet_model =ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "googleNet_model.trainable = True\n",
    "\n",
    "model = Sequential()\n",
    "model.add(googleNet_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "567/567 [==============================] - 213s 353ms/step - loss: 0.3754 - accuracy: 0.8263 - val_loss: 1.2766 - val_accuracy: 0.4423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "567/567 [==============================] - 140s 247ms/step - loss: 0.2190 - accuracy: 0.9094 - val_loss: 0.4745 - val_accuracy: 0.8029\n",
      "Epoch 3/20\n",
      "567/567 [==============================] - 148s 261ms/step - loss: 0.1716 - accuracy: 0.9313 - val_loss: 0.2662 - val_accuracy: 0.8947\n",
      "Epoch 4/20\n",
      "567/567 [==============================] - 143s 252ms/step - loss: 0.1418 - accuracy: 0.9421 - val_loss: 0.2712 - val_accuracy: 0.8949\n",
      "Epoch 5/20\n",
      "567/567 [==============================] - 150s 265ms/step - loss: 0.1226 - accuracy: 0.9496 - val_loss: 0.1198 - val_accuracy: 0.9574\n",
      "Epoch 6/20\n",
      "567/567 [==============================] - 140s 247ms/step - loss: 0.1106 - accuracy: 0.9577 - val_loss: 0.1789 - val_accuracy: 0.9369\n",
      "Epoch 7/20\n",
      "567/567 [==============================] - 138s 243ms/step - loss: 0.0998 - accuracy: 0.9617 - val_loss: 0.1121 - val_accuracy: 0.9623\n",
      "Epoch 8/20\n",
      "567/567 [==============================] - 134s 236ms/step - loss: 0.0902 - accuracy: 0.9659 - val_loss: 0.1128 - val_accuracy: 0.9585\n",
      "Epoch 9/20\n",
      "567/567 [==============================] - 133s 234ms/step - loss: 0.0783 - accuracy: 0.9702 - val_loss: 0.0871 - val_accuracy: 0.9669\n",
      "Epoch 10/20\n",
      "567/567 [==============================] - 132s 232ms/step - loss: 0.0807 - accuracy: 0.9684 - val_loss: 0.1468 - val_accuracy: 0.9477\n",
      "Epoch 11/20\n",
      "567/567 [==============================] - 132s 233ms/step - loss: 0.0701 - accuracy: 0.9737 - val_loss: 0.0864 - val_accuracy: 0.9715\n",
      "Epoch 12/20\n",
      "567/567 [==============================] - 132s 233ms/step - loss: 0.0668 - accuracy: 0.9761 - val_loss: 0.0993 - val_accuracy: 0.9653\n",
      "Epoch 13/20\n",
      "567/567 [==============================] - 136s 239ms/step - loss: 0.0627 - accuracy: 0.9759 - val_loss: 0.0907 - val_accuracy: 0.9704\n",
      "Epoch 14/20\n",
      "567/567 [==============================] - 132s 232ms/step - loss: 0.0595 - accuracy: 0.9767 - val_loss: 0.0932 - val_accuracy: 0.9709\n",
      "Epoch 15/20\n",
      "567/567 [==============================] - 132s 233ms/step - loss: 0.0564 - accuracy: 0.9790 - val_loss: 0.0961 - val_accuracy: 0.9676\n",
      "Epoch 16/20\n",
      "567/567 [==============================] - 134s 236ms/step - loss: 0.0565 - accuracy: 0.9784 - val_loss: 0.0897 - val_accuracy: 0.9784\n",
      "Epoch 17/20\n",
      "567/567 [==============================] - 133s 234ms/step - loss: 0.0471 - accuracy: 0.9813 - val_loss: 0.0960 - val_accuracy: 0.9715\n",
      "Epoch 18/20\n",
      "567/567 [==============================] - 133s 234ms/step - loss: 0.0524 - accuracy: 0.9799 - val_loss: 0.1089 - val_accuracy: 0.9673\n",
      "Epoch 19/20\n",
      "567/567 [==============================] - 132s 233ms/step - loss: 0.0433 - accuracy: 0.9844 - val_loss: 0.0707 - val_accuracy: 0.9759\n",
      "Epoch 20/20\n",
      "567/567 [==============================] - 132s 233ms/step - loss: 0.0397 - accuracy: 0.9846 - val_loss: 0.0966 - val_accuracy: 0.9724\n"
     ]
    }
   ],
   "source": [
    "checkpoint=tf.keras.callbacks.ModelCheckpoint(\n",
    "   '2resnet50.h5',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE =32\n",
    "history = model.fit(train_gen, batch_size = BATCH_SIZE, epochs = EPOCHS, validation_data = val_gen, verbose = 1,callbacks=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 218 images belonging to 1 classes.\n",
      "218/218 [==============================] - 8s 37ms/step\n",
      "all_positive\n",
      "193\n",
      "25\n",
      " \n",
      "Found 3616 images belonging to 1 classes.\n",
      "3616/3616 [==============================] - 79s 22ms/step\n",
      "all_positive\n",
      "3368\n",
      "248\n",
      " \n",
      "Found 8000 images belonging to 1 classes.\n",
      "8000/8000 [==============================] - 180s 23ms/step\n",
      "all_negative\n",
      "508\n",
      "7492\n",
      " \n",
      "Found 2192 images belonging to 1 classes.\n",
      "2192/2192 [==============================] - 50s 23ms/step\n",
      "all_negative\n",
      "157\n",
      "2035\n",
      " \n"
     ]
    }
   ],
   "source": [
    "test_datagen = image.ImageDataGenerator(rescale=1./255)\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "        'covid',\n",
    "        target_size=(128,128),\n",
    "        batch_size=1,\n",
    "        class_mode='binary',\n",
    "        shuffle=False)\n",
    "pred= model.predict(test_gen, verbose=1)\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "count0=0\n",
    "count1=0\n",
    "for val in range(len(pred)):\n",
    "    if predicted_class_indices[val]==0:\n",
    "        count0=count0+1\n",
    "    else:\n",
    "        count1=count1+1\n",
    "print(\"all_positive\")        \n",
    "print(count0)\n",
    "print(count1)\n",
    "print(\" \")\n",
    "\n",
    "############################################\n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "        'data/cov',\n",
    "        target_size=(128,128),\n",
    "        batch_size=1,\n",
    "        class_mode='binary',\n",
    "        shuffle=False)\n",
    "pred= model.predict(test_gen, verbose=1)\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "count0=0\n",
    "count1=0\n",
    "for val in range(len(pred)):\n",
    "    if predicted_class_indices[val]==0:\n",
    "        count0=count0+1\n",
    "    else:\n",
    "        count1=count1+1\n",
    "print(\"all_positive\")        \n",
    "print(count0)\n",
    "print(count1)\n",
    "print(\" \")\n",
    "\n",
    "##############################################\n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "        'data/nor',\n",
    "        target_size=(128,128),\n",
    "        batch_size=1,\n",
    "        class_mode='binary',\n",
    "        shuffle=False)\n",
    "pred= model.predict(test_gen, verbose=1)\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "count0=0\n",
    "count1=0\n",
    "for val in range(len(pred)):\n",
    "    if predicted_class_indices[val]==0:\n",
    "        count0=count0+1\n",
    "    else:\n",
    "        count1=count1+1\n",
    "print(\"all_negative\")\n",
    "print(count0)\n",
    "print(count1)\n",
    "print(\" \")\n",
    "\n",
    "###############################################\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "        'norm',\n",
    "        target_size=(128,128),\n",
    "        batch_size=1,\n",
    "        class_mode='binary',\n",
    "        shuffle=False)\n",
    "pred= model.predict(test_gen, verbose=1)\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "count0=0\n",
    "count1=0\n",
    "for val in range(len(pred)):\n",
    "    if predicted_class_indices[val]==0:\n",
    "        count0=count0+1\n",
    "    else:\n",
    "        count1=count1+1\n",
    "print(\"all_negative\")\n",
    "print(count0)\n",
    "print(count1)\n",
    "print(\" \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#data=[]\n",
    "#path='test/DLAI3_CXR_Validation_Set'\n",
    "#for img in os.listdir(path): \n",
    "#    data.append(img) \n",
    "\n",
    "#df=pd.DataFrame(data,columns = ['Filename'])\n",
    "#df['label']=0\n",
    "#df['label']=predicted_class_indices\n",
    "#df['label'].replace({1:0, 0:1}, inplace=True) \n",
    "#df.to_csv('InceptionResNetV2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[224,224, 3]))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "cnn.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "cnn.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "cnn.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dropout(0.5))\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint=tf.keras.callbacks.ModelCheckpoint( '7.h5',save_best_only=True)\n",
    "cnn.fit(x = train_gen, validation_data = val_gen, epochs =20,callbacks=checkpoint )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 1 classes.\n",
      "8000/8000 [==============================] - 94s 12ms/step\n",
      "test\n",
      "822\n",
      "7178\n"
     ]
    }
   ],
   "source": [
    "test_gen = test_datagen.flow_from_directory(\n",
    "        'data/nor',\n",
    "        target_size=(128,128),\n",
    "        batch_size=1,\n",
    "        class_mode='binary',\n",
    "        shuffle=False)\n",
    "pred= model.predict(test_gen, verbose=1)\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "count0=0\n",
    "count1=0\n",
    "for val in range(len(pred)):\n",
    "    if predicted_class_indices[val]==0:\n",
    "        count0=count0+1\n",
    "    else:\n",
    "        count1=count1+1\n",
    "print(\"test\")\n",
    "print(count0)\n",
    "print(count1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model(\"2resnet50.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50=94.07\n",
    "inceptionv3=84.32"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
